{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection of ANN in Intestinal Absortion Prediction\n",
    "\n",
    "This section presents the model selection of Artificial Neural Network in Intestinal Absortition Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset for training\n",
    "\n",
    "\n",
    "- FC-1: NHA, LogP, MolWt, NAR, NRB, tPSA, NHD, fcSP3\n",
    "- FC-2: NHA, LogP, tPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_Train = joblib.load('./Dataset_Training_Test/Data_Train.pkl')\n",
    "\n",
    "Data = pd.read_excel('dataset_HIA_geral.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Feature Composition\n",
    "FC = 2\n",
    "\n",
    "if FC == 1:\n",
    "    X_Train = Data.drop(['Name','SMILES','Output'], axis=1)[0:140].values\n",
    "    X_Test = Data.drop(['Name','SMILES','Output'], axis=1)[140:].values\n",
    "    \n",
    "else:\n",
    "    X_Train = Data[['WLOGP','tPSA','NHA']][0:140].values \n",
    "    X_Test = Data[['WLOGP','tPSA','NHA']][140:].values\n",
    "    \n",
    "\n",
    "y_Train = Data[['Output']][0:140].values.ravel()\n",
    "y_Test = Data[['Output']][140:].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "\n",
    "Scaler = MinMaxScaler().fit(X_Train)\n",
    "\n",
    "X_train = Scaler.transform(X_Train)  \n",
    "X_test = Scaler.transform(X_Test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model_ANN_FC2/scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(Scaler,'./Model_ANN_FC2/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of ANN models\n",
    "\n",
    "param_grid = [{'activation': ['relu','tanh'],\n",
    "               'hidden_layer_sizes': [(20), (30), (40), (50), (60), (20,20), (30,30), (40,40), (50,50), (60,60)]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "ANN = MLPClassifier(solver = 'adam', max_iter = 2000, learning_rate = 'adaptive', random_state=0)\n",
    "\n",
    "\n",
    "GS = GridSearchCV(ANN, param_grid, cv=10, scoring='accuracy',return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=MLPClassifier(learning_rate='adaptive', max_iter=2000,\n",
       "                                     random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'activation': ['relu', 'tanh'],\n",
       "                          'hidden_layer_sizes': [20, 30, 40, 50, 60, (20, 20),\n",
       "                                                 (30, 30), (40, 40), (50, 50),\n",
       "                                                 (60, 60)]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model_ANN_FC2/GridSearch_ANN.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving grid search\n",
    "\n",
    "joblib.dump(GS,'./Model_ANN_FC2/GridSearch_ANN.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating and Selecting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading grid search\n",
    "\n",
    "GS_ANN = joblib.load('./Model_ANN_FC2/GridSearch_ANN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30), learning_rate='adaptive',\n",
       "              max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimator\n",
    "\n",
    "GS_ANN.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Index = 7\n"
     ]
    }
   ],
   "source": [
    "# index of best model\n",
    "\n",
    "print('Best Index = {}'.format(GS_ANN.best_index_+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'hidden_layer_sizes': (30, 30)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "\n",
    "GS_ANN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Evaluation\n",
      "M1: 0.764286 +- 0.110887 {'activation': 'relu', 'hidden_layer_sizes': 20}\n",
      "M2: 0.771429 +- 0.104978 {'activation': 'relu', 'hidden_layer_sizes': 30}\n",
      "M3: 0.778571 +- 0.092857 {'activation': 'relu', 'hidden_layer_sizes': 40}\n",
      "M4: 0.771429 +- 0.1 {'activation': 'relu', 'hidden_layer_sizes': 50}\n",
      "M5: 0.764286 +- 0.110887 {'activation': 'relu', 'hidden_layer_sizes': 60}\n",
      "M6: 0.778571 +- 0.092857 {'activation': 'relu', 'hidden_layer_sizes': (20, 20)}\n",
      "M7: 0.842857 +- 0.089214 {'activation': 'relu', 'hidden_layer_sizes': (30, 30)}\n",
      "M8: 0.835714 +- 0.084817 {'activation': 'relu', 'hidden_layer_sizes': (40, 40)}\n",
      "M9: 0.821429 +- 0.086011 {'activation': 'relu', 'hidden_layer_sizes': (50, 50)}\n",
      "M10: 0.842857 +- 0.089214 {'activation': 'relu', 'hidden_layer_sizes': (60, 60)}\n",
      "M11: 0.764286 +- 0.110887 {'activation': 'tanh', 'hidden_layer_sizes': 20}\n",
      "M12: 0.764286 +- 0.110887 {'activation': 'tanh', 'hidden_layer_sizes': 30}\n",
      "M13: 0.764286 +- 0.110887 {'activation': 'tanh', 'hidden_layer_sizes': 40}\n",
      "M14: 0.778571 +- 0.092857 {'activation': 'tanh', 'hidden_layer_sizes': 50}\n",
      "M15: 0.771429 +- 0.1 {'activation': 'tanh', 'hidden_layer_sizes': 60}\n",
      "M16: 0.821429 +- 0.091752 {'activation': 'tanh', 'hidden_layer_sizes': (20, 20)}\n",
      "M17: 0.814286 +- 0.091473 {'activation': 'tanh', 'hidden_layer_sizes': (30, 30)}\n",
      "M18: 0.814286 +- 0.091473 {'activation': 'tanh', 'hidden_layer_sizes': (40, 40)}\n",
      "M19: 0.814286 +- 0.091473 {'activation': 'tanh', 'hidden_layer_sizes': (50, 50)}\n",
      "M20: 0.814286 +- 0.091473 {'activation': 'tanh', 'hidden_layer_sizes': (60, 60)}\n"
     ]
    }
   ],
   "source": [
    "# scores by model\n",
    "\n",
    "cvres = GS_ANN.cv_results_\n",
    "\n",
    "print('ANN Evaluation')\n",
    "k=1\n",
    "for mean_score, standard, params in zip(cvres[\"mean_test_score\"], cvres[\"std_test_score\"], cvres[\"params\"]):\n",
    "    print('M{}:'.format(k), round(mean_score,6), '+- {}'.format(round(standard,6)), params)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the CV scores by each Feaature Composition\n",
    "\n",
    "Nmodels = len(GS_ANN.cv_results_[\"params\"])\n",
    "\n",
    "col_scr=[]\n",
    "row_scr=[]\n",
    "\n",
    "for k in range(10):\n",
    "    col_scr.insert(k,'CV_{}'.format(k+1))\n",
    "    \n",
    "    \n",
    "for j in range(Nmodels):\n",
    "    row_scr.insert(j,'M{}'.format(j+1))\n",
    "\n",
    "    \n",
    "df_scores=[]    \n",
    "for k in range(10):\n",
    "\n",
    "    cvres = GS_ANN.cv_results_\n",
    "    score_valid=np.concatenate((cvres['split0_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split1_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split2_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split3_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split4_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split5_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split6_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split7_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split8_test_score'].reshape(Nmodels,1),\n",
    "                            cvres['split9_test_score'].reshape(Nmodels,1)),axis=1) \n",
    "    df_scores = pd.DataFrame(data=score_valid,index=row_scr,columns=col_scr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV_1</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_3</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_4</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_5</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_6</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_7</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_8</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_9</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_10</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             M1        M2        M3        M4        M5        M6        M7  \\\n",
       "CV_1   0.642857  0.642857  0.642857  0.642857  0.642857  0.642857  0.642857   \n",
       "CV_2   0.571429  0.571429  0.642857  0.642857  0.571429  0.642857  0.785714   \n",
       "CV_3   0.857143  0.857143  0.857143  0.857143  0.857143  0.857143  0.928571   \n",
       "CV_4   0.928571  0.928571  0.928571  0.928571  0.928571  0.928571  0.928571   \n",
       "CV_5   0.857143  0.857143  0.857143  0.857143  0.857143  0.857143  0.857143   \n",
       "CV_6   0.785714  0.785714  0.785714  0.785714  0.785714  0.857143  0.928571   \n",
       "CV_7   0.642857  0.714286  0.714286  0.642857  0.642857  0.714286  0.785714   \n",
       "CV_8   0.857143  0.857143  0.857143  0.857143  0.857143  0.785714  0.928571   \n",
       "CV_9   0.785714  0.785714  0.785714  0.785714  0.785714  0.785714  0.857143   \n",
       "CV_10  0.714286  0.714286  0.714286  0.714286  0.714286  0.714286  0.785714   \n",
       "\n",
       "             M8        M9       M10       M11       M12       M13       M14  \\\n",
       "CV_1   0.642857  0.642857  0.642857  0.642857  0.642857  0.642857  0.642857   \n",
       "CV_2   0.785714  0.785714  0.785714  0.571429  0.571429  0.571429  0.642857   \n",
       "CV_3   0.928571  0.928571  0.928571  0.857143  0.857143  0.857143  0.857143   \n",
       "CV_4   0.928571  0.928571  0.928571  0.928571  0.928571  0.928571  0.928571   \n",
       "CV_5   0.857143  0.857143  0.857143  0.857143  0.857143  0.857143  0.857143   \n",
       "CV_6   0.857143  0.857143  0.928571  0.785714  0.785714  0.785714  0.785714   \n",
       "CV_7   0.785714  0.785714  0.785714  0.642857  0.642857  0.642857  0.714286   \n",
       "CV_8   0.928571  0.857143  0.928571  0.857143  0.857143  0.857143  0.857143   \n",
       "CV_9   0.857143  0.857143  0.857143  0.785714  0.785714  0.785714  0.785714   \n",
       "CV_10  0.785714  0.714286  0.785714  0.714286  0.714286  0.714286  0.714286   \n",
       "\n",
       "            M15       M16       M17       M18       M19       M20  \n",
       "CV_1   0.642857  0.642857  0.642857  0.642857  0.642857  0.642857  \n",
       "CV_2   0.642857  0.785714  0.785714  0.785714  0.785714  0.785714  \n",
       "CV_3   0.857143  0.928571  0.928571  0.928571  0.928571  0.928571  \n",
       "CV_4   0.928571  0.928571  0.928571  0.928571  0.928571  0.928571  \n",
       "CV_5   0.857143  0.857143  0.857143  0.857143  0.857143  0.857143  \n",
       "CV_6   0.785714  0.857143  0.785714  0.785714  0.785714  0.785714  \n",
       "CV_7   0.642857  0.785714  0.785714  0.785714  0.785714  0.785714  \n",
       "CV_8   0.857143  0.928571  0.928571  0.928571  0.928571  0.928571  \n",
       "CV_9   0.785714  0.785714  0.785714  0.785714  0.785714  0.785714  \n",
       "CV_10  0.714286  0.714286  0.714286  0.714286  0.714286  0.714286  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.116885</td>\n",
       "      <td>0.110657</td>\n",
       "      <td>0.097880</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>0.116885</td>\n",
       "      <td>0.097880</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.089405</td>\n",
       "      <td>0.090664</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.116885</td>\n",
       "      <td>0.116885</td>\n",
       "      <td>0.116885</td>\n",
       "      <td>0.097880</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.096421</td>\n",
       "      <td>0.096421</td>\n",
       "      <td>0.096421</td>\n",
       "      <td>0.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              M1         M2         M3         M4         M5         M6  \\\n",
       "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
       "mean    0.764286   0.771429   0.778571   0.771429   0.764286   0.778571   \n",
       "std     0.116885   0.110657   0.097880   0.105409   0.116885   0.097880   \n",
       "min     0.571429   0.571429   0.642857   0.642857   0.571429   0.642857   \n",
       "25%     0.660714   0.714286   0.714286   0.660714   0.660714   0.714286   \n",
       "50%     0.785714   0.785714   0.785714   0.785714   0.785714   0.785714   \n",
       "75%     0.857143   0.857143   0.857143   0.857143   0.857143   0.857143   \n",
       "max     0.928571   0.928571   0.928571   0.928571   0.928571   0.928571   \n",
       "\n",
       "              M7         M8         M9        M10        M11        M12  \\\n",
       "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
       "mean    0.842857   0.835714   0.821429   0.842857   0.764286   0.764286   \n",
       "std     0.094040   0.089405   0.090664   0.094040   0.116885   0.116885   \n",
       "min     0.642857   0.642857   0.642857   0.642857   0.571429   0.571429   \n",
       "25%     0.785714   0.785714   0.785714   0.785714   0.660714   0.660714   \n",
       "50%     0.857143   0.857143   0.857143   0.857143   0.785714   0.785714   \n",
       "75%     0.928571   0.910714   0.857143   0.928571   0.857143   0.857143   \n",
       "max     0.928571   0.928571   0.928571   0.928571   0.928571   0.928571   \n",
       "\n",
       "             M13        M14        M15        M16        M17        M18  \\\n",
       "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
       "mean    0.764286   0.778571   0.771429   0.821429   0.814286   0.814286   \n",
       "std     0.116885   0.097880   0.105409   0.096715   0.096421   0.096421   \n",
       "min     0.571429   0.642857   0.642857   0.642857   0.642857   0.642857   \n",
       "25%     0.660714   0.714286   0.660714   0.785714   0.785714   0.785714   \n",
       "50%     0.785714   0.785714   0.785714   0.821429   0.785714   0.785714   \n",
       "75%     0.857143   0.857143   0.857143   0.910714   0.910714   0.910714   \n",
       "max     0.928571   0.928571   0.928571   0.928571   0.928571   0.928571   \n",
       "\n",
       "             M19        M20  \n",
       "count  10.000000  10.000000  \n",
       "mean    0.814286   0.814286  \n",
       "std     0.096421   0.096421  \n",
       "min     0.642857   0.642857  \n",
       "25%     0.785714   0.785714  \n",
       "50%     0.785714   0.785714  \n",
       "75%     0.910714   0.910714  \n",
       "max     0.928571   0.928571  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.05)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(dpi=300)\n",
    "\n",
    "sns.catplot(kind=\"box\",data=df_scores, height=4.5, aspect=2, palette='Set1')\n",
    "\n",
    "plt.xlabel('ANN model',labelpad=10,fontsize=15)\n",
    "plt.ylabel('Accuracy',labelpad=10,fontsize=15)\n",
    "plt.ylim(0.5, 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model_ANN_FC2/ANN_best_model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving best model\n",
    "\n",
    "joblib.dump(GS_ANN.best_estimator_,'./Model_ANN_FC2/ANN_best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model_ANN_FC2/df_scores.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving results\n",
    "\n",
    "joblib.dump(df_scores,'./Model_ANN_FC2/df_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving figure\n",
    "\n",
    "#fig1.savefig('./Model_ANN_FC2/fig_ANN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_best = GS_ANN.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ANN_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89        21\n",
      "           1       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.92      0.90      0.90        42\n",
      "weighted avg       0.92      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_Test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy = 0.9047619047619048'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Sensitivity = 1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Specificity = 0.8095238095238095'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_Test,y_pred).ravel()\n",
    "display('Accuracy = {}'.format((tp+tn)/(tp+tn+fp+fn)))\n",
    "display('Sensitivity = {}'.format(tp/(tp+fn)))\n",
    "display('Specificity = {}'.format(tn/(tn+fp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
